% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_links_pagesource_html.R
\name{get_html}
\alias{get_html}
\title{Automatically download content of websites.}
\usage{
get_html(pagesource, case)
}
\arguments{
\item{pagesource}{A character vector which contains the page sources of all websites.}

\item{case}{The name of the case, e.g. a country, make it a unique case identifier.}
}
\value{
A folder with all htmls scraped from the target website.
}
\description{
A function to automatically download content of websites via their page source and save them as html in a folder.
}
\examples{
#Don't run
#Get the contents of links provided on a website
#get_html()

}
